{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/workspace/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from diskcache import Cache\n",
    "import os\n",
    "from Utils.data_manager import DataManager\n",
    "from Utils.models import FMNIST_Net\n",
    "from Clients.training import Training\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from Utils.analytics import Analytics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class FULDebug:\n",
    "    def __init__(self, cache, breakpoint, num_parties, num_fl_rounds):\n",
    "        \n",
    "        cache[\"breakpoint\"] = breakpoint\n",
    "        self.num_parties = num_parties\n",
    "        self.num_fl_rounds = num_fl_rounds\n",
    "        self.cache = cache\n",
    "    \n",
    "    def average_selected_models(self, selected_parties, party_models):\n",
    "        with torch.no_grad():\n",
    "            sum_vec = nn.utils.parameters_to_vector(party_models[selected_parties[0]].parameters())\n",
    "            if len(selected_parties) > 1:\n",
    "                for i in range(1,len(selected_parties)):\n",
    "                    sum_vec += nn.utils.parameters_to_vector(party_models[selected_parties[i]].parameters())\n",
    "                sum_vec /= len(selected_parties)\n",
    "\n",
    "            model = copy.deepcopy(party_models[0])\n",
    "            nn.utils.vector_to_parameters(sum_vec, model.parameters())\n",
    "        return model.state_dict()\n",
    "    \n",
    "    def aggregate(self, client_models, current_model=None):\n",
    "        selected_parties = [i for i in range(self.num_parties)]\n",
    "        aggregated_model_state_dict = self.average_selected_models(selected_parties, client_models)\n",
    "        return aggregated_model_state_dict \n",
    "    \n",
    "    def partiesStart(self, trainloader_lst, testloader, client_to_be_erased=100, dataType=\"FMNIST\"):\n",
    "\n",
    "        num_fl_rounds = self.num_fl_rounds\n",
    "        num_parties = self.num_parties\n",
    "        initial_model = FMNIST_Net()\n",
    "        model_dict = copy.deepcopy(initial_model.state_dict())\n",
    "        client_models_all_rounds = []\n",
    "        global_models_all_rounds = []\n",
    "        for round_num in range(num_fl_rounds): \n",
    "            ##################### Local Training Round #############################\n",
    "            current_model_state_dict = copy.deepcopy(model_dict)\n",
    "            current_model = copy.deepcopy(initial_model)\n",
    "            current_model.load_state_dict(current_model_state_dict)\n",
    "            client_models = []\n",
    "            party_losses = []\n",
    "            for party_id in range(num_parties):\n",
    "\n",
    "                if party_id == client_to_be_erased:\n",
    "                    client_models.append(FMNIST_Net())\n",
    "                else:\n",
    "                    model = copy.deepcopy(current_model)\n",
    "                    local_training = Training(num_updates_in_epoch=None, num_local_epochs=1)\n",
    "                    model_update, party_loss = local_training.train(model=model, \n",
    "                                                trainloader=trainloader_lst[party_id], \n",
    "                                                criterion=None, opt=None, dataType=dataType)\n",
    "\n",
    "                    client_models.append(copy.deepcopy(model_update))\n",
    "                    party_losses.append(party_loss)\n",
    "                    print(f\"Party {party_id} Loss: {party_loss}\")\n",
    "            ######################################################################  \n",
    "            current_model_state_dict = self.aggregate(client_models=client_models, current_model=current_model)\n",
    "            model_dict = copy.deepcopy(current_model_state_dict)\n",
    "            eval_model = FMNIST_Net()\n",
    "            eval_model.load_state_dict(current_model_state_dict)\n",
    "            clean_acc = local_training.evaluate(testloader, eval_model)\n",
    "            client_models_all_rounds.append(copy.deepcopy(client_models))\n",
    "            global_models_all_rounds.append(copy.deepcopy(current_model_state_dict))\n",
    "            # clean_accuracy[fusion_key][round_num] = clean_acc        \n",
    "            self.cache[f\"client_models\"] = client_models\n",
    "            self.cache[f\"global_models\"] = current_model_state_dict\n",
    "            print(f'Global Clean Accuracy, round {round_num} = {clean_acc}')\n",
    "\n",
    "        self.cache[\"client_models_all_rounds\"] = client_models_all_rounds\n",
    "        self.cache[\"global_models_all_rounds\"] = global_models_all_rounds\n",
    "\n",
    "    # Function to compute class-wise accuracy\n",
    "    def compute_classwise_metrics(self, model, test_loader):\n",
    "        class_correct = defaultdict(int)\n",
    "        class_total = defaultdict(int)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, labels in test_loader:\n",
    "                if data.dim() == 5:  # If the image has an extra dimension, squeeze it\n",
    "                    data = data.squeeze(1)  # Remove the extra dimension\n",
    "                    \n",
    "                # Check if the input tensor has the correct shape for CIFAR-10\n",
    "                if data.shape[1] == 32:  # Indicates the channel dimension is incorrectly set as 32\n",
    "                    # Permute from [batch_size, height, width, channels] to [batch_size, channels, height, width]\n",
    "                    data = data.permute(0, 3, 1, 2)\n",
    "                    \n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                # Update class-wise correct/total counts\n",
    "                for label, prediction in zip(labels, predicted):\n",
    "                    class_total[label.item()] += 1\n",
    "                    if label.item() == prediction.item():\n",
    "                        class_correct[label.item()] += 1\n",
    "        \n",
    "        # Compute class-wise accuracies\n",
    "        class_accuracies = {cls: class_correct[cls] / class_total[cls] if class_total[cls] > 0 else 0\n",
    "                            for cls in class_total}\n",
    "        \n",
    "        return class_accuracies, class_total\n",
    "\n",
    "    # Function to identify classes impacted by unlearning\n",
    "    def identify_affected_classes(self, global_model_before, global_model_after, test_loader, threshold=0.05):\n",
    "        \"\"\"\n",
    "        Identify the classes that are significantly impacted after unlearning client 0.\n",
    "        \n",
    "        :param global_model_before: The global model before unlearning.\n",
    "        :param global_model_after: The global model after unlearning.\n",
    "        :param test_loader: The test data loader.\n",
    "        :param threshold: The threshold to consider a class significantly impacted.\n",
    "        :return: A list of impacted classes.\n",
    "        \"\"\"\n",
    "        # Compute class-wise accuracy before and after unlearning\n",
    "        before_class_accuracies, _ = self.compute_classwise_metrics(global_model_before, test_loader)\n",
    "        after_class_accuracies, _ = self.compute_classwise_metrics(global_model_after, test_loader)\n",
    "    \n",
    "        impacted_classes = []\n",
    "    \n",
    "        # Compare class accuracies before and after unlearning\n",
    "        for cls in before_class_accuracies:\n",
    "            accuracy_drop = before_class_accuracies[cls] - after_class_accuracies[cls]\n",
    "            if accuracy_drop > threshold:\n",
    "                impacted_classes.append(cls)\n",
    "    \n",
    "        return impacted_classes\n",
    "\n",
    "    def calculate_class_weights(self, global_model_before, global_model_after, test_loader, impacted_classes):\n",
    "        \"\"\"\n",
    "        Calculate class weights based on the accuracy difference before and after unlearning.\n",
    "        \n",
    "        :param global_model_before: Global model before unlearning.\n",
    "        :param global_model_after: Global model after unlearning.\n",
    "        :param test_loader: DataLoader for the test data.\n",
    "        :param impacted_classes: List of impacted classes.\n",
    "        :return: Dictionary with class indices as keys and weights as values.\n",
    "        \"\"\"\n",
    "        # Compute class-wise accuracies before and after unlearning\n",
    "        class_accuracies_before, _ = self.compute_classwise_metrics(global_model_before, test_loader)\n",
    "        class_accuracies_after, _ = self.compute_classwise_metrics(global_model_after, test_loader)\n",
    "        \n",
    "        # Calculate the absolute difference in accuracy for each impacted class\n",
    "        accuracy_diffs = {class_idx: abs(class_accuracies_before[class_idx] - class_accuracies_after[class_idx])\n",
    "                          for class_idx in impacted_classes}\n",
    "        \n",
    "        # Normalize the differences to sum to 1 (to be used as weights)\n",
    "        total_diff = sum(accuracy_diffs.values())\n",
    "        class_weights = {class_idx: (diff / total_diff) for class_idx, diff in accuracy_diffs.items()} if total_diff > 0 else {class_idx: 1/len(impacted_classes) for class_idx in impacted_classes}\n",
    "        \n",
    "        # Print class weights for reference\n",
    "        for class_idx, weight in class_weights.items():\n",
    "            print(f\"Class {class_idx} Weight: {weight:.4f}\")\n",
    "        \n",
    "        return class_weights\n",
    "\n",
    "    \n",
    "    def select_clients_to_fix_bias(self, clients_models, impacted_classes, test_loader, global_model, global_model_before, global_model_after, num_clients=3, lambda_penalty=0.1):\n",
    "        \"\"\"\n",
    "        Select clients that contribute the most to the affected classes with automated class weighting and regularization.\n",
    "        \n",
    "        :param clients_models: List of models for remaining clients.\n",
    "        :param impacted_classes: List of classes impacted by unlearning client 0.\n",
    "        :param test_loader: DataLoader for the test data.\n",
    "        :param global_model: Global model to compute deviations for regularization.\n",
    "        :param global_model_before: Global model before unlearning.\n",
    "        :param global_model_after: Global model after unlearning.\n",
    "        :param num_clients: Number of clients to select for fixing the bias.\n",
    "        :param lambda_penalty: Regularization term to penalize clients with large deviations from global performance.\n",
    "        :return: Tuple of (list of selected client indices, list of selected client models).\n",
    "        \"\"\"\n",
    "        # Automatically assign class weights based on accuracy impact\n",
    "        class_weights = self.calculate_class_weights(global_model_before, global_model_after, test_loader, impacted_classes)\n",
    "    \n",
    "        client_contributions = []\n",
    "        \n",
    "        # Compute global model's class-wise accuracy for regularization\n",
    "        global_class_accuracies, _ = self.compute_classwise_metrics(global_model, test_loader)\n",
    "        \n",
    "        # Compute class-wise accuracy for each client\n",
    "        for client_idx, client_model in enumerate(clients_models):\n",
    "            class_accuracies, _ = self.compute_classwise_metrics(client_model, test_loader)\n",
    "            \n",
    "            # Calculate the weighted contribution of this client to the impacted classes\n",
    "            contribution = sum((class_accuracies[class_idx] * class_weights[class_idx]) for class_idx in impacted_classes)\n",
    "            \n",
    "            # Compute the regularization term: deviation from the global model\n",
    "            deviation_penalty = sum(abs(class_accuracies[class_idx] - global_class_accuracies[class_idx]) for class_idx in impacted_classes)\n",
    "            \n",
    "            # Final score: contribution minus regularization penalty\n",
    "            final_contribution = contribution - lambda_penalty * deviation_penalty\n",
    "            \n",
    "            client_contributions.append((client_idx, client_model, final_contribution))\n",
    "        \n",
    "        # Sort clients by their final contribution score\n",
    "        client_contributions.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Select top clients to fix the bias\n",
    "        selected_clients = client_contributions[:num_clients]\n",
    "        \n",
    "        # Extract client indices and models for the selected clients\n",
    "        selected_client_indices = [client_idx for client_idx, _, _ in selected_clients]\n",
    "        selected_client_models = [client_model for _, client_model, _ in selected_clients]\n",
    "        \n",
    "        # Print selected clients and their contributions\n",
    "        for client_idx, _, contribution in selected_clients:\n",
    "            print(f\"Selected Client {client_idx} with Contribution: {contribution:.4f}\")\n",
    "        \n",
    "        # Return both selected client indices and models\n",
    "        return selected_client_models, selected_client_indices\n",
    "\n",
    "\n",
    "    def unlearnedModelAggregationWithSelectedClients(self, trainloader_lst, testloader, unlearned_model, num_rounds=10, client_to_be_erased=100, select_clients_method='random', select_num_clients=6):\n",
    "    \n",
    "        num_parties = self.num_parties\n",
    "        initial_model = FMNIST_Net()\n",
    "        current_model_state_dict = copy.deepcopy(unlearned_model.state_dict())  \n",
    "        initial_model.load_state_dict(current_model_state_dict)  \n",
    "        model_dict = copy.deepcopy(initial_model.state_dict())\n",
    "\n",
    "        model_before = self.cache.get('initial_model')\n",
    "        model_before.load_state_dict(self.cache.get('global_models'))\n",
    "        model_before.eval()\n",
    "        \n",
    "        model_after = self.cache.get('initial_model')\n",
    "        model_after.load_state_dict(self.cache.get(\"unlearned_model\").state_dict())\n",
    "        model_after.eval()\n",
    "        \n",
    "        client_model = self.cache.get('initial_model')\n",
    "        client_model.load_state_dict(self.cache.get(\"client_models\")[0].state_dict())\n",
    "        client_model.eval()\n",
    "        \n",
    "        global_model_accuracies = []\n",
    "        for round_num in range(num_rounds): \n",
    "            ##################### Local Training Round #############################\n",
    "            current_model_state_dict = copy.deepcopy(model_dict)\n",
    "            current_model = copy.deepcopy(initial_model)\n",
    "            current_model.load_state_dict(current_model_state_dict)\n",
    "            client_models = []\n",
    "            party_losses = []\n",
    "    \n",
    "            for party_id in range(num_parties):\n",
    "                if party_id == client_to_be_erased:\n",
    "                    client_models.append(FMNIST_Net())  # Placeholder for unlearned client\n",
    "                else:\n",
    "                    model = copy.deepcopy(current_model)\n",
    "                    local_training = Training(num_updates_in_epoch=None, num_local_epochs=1)\n",
    "                    model_update, party_loss = local_training.train(model=model, \n",
    "                                                    trainloader=trainloader_lst[party_id], \n",
    "                                                    criterion=None, opt=None, dataType=\"CIFAR\")\n",
    "    \n",
    "                    client_models.append(copy.deepcopy(model_update))\n",
    "                    party_losses.append(party_loss)\n",
    "                    print(f\"Party {party_id} Loss: {party_loss}\")\n",
    "    \n",
    "            ###################### Client Selection ###############################\n",
    "            impacted_classes = self.identify_affected_classes(model_before, model_after, testDataloader, threshold=0.05)\n",
    "            selected_client_models, selected_client_indices = self.select_clients_to_fix_bias(client_models, impacted_classes, testDataloader, model_before, model_before, model_after, num_clients=5)\n",
    "            print(selected_client_models)\n",
    "    \n",
    "            #######################################################################\n",
    "            # Aggregate only the selected client models\n",
    "            current_model_state_dict = self.unlearnAggregate(client_models=selected_client_models, client_to_be_erased=client_to_be_erased)\n",
    "            model_dict = copy.deepcopy(current_model_state_dict)\n",
    "            eval_model = FMNIST_Net()\n",
    "            eval_model.load_state_dict(current_model_state_dict)\n",
    "    \n",
    "            clean_acc = local_training.evaluate(testloader, eval_model)\n",
    "            print(f'Global Clean Accuracy, round {round_num} = {clean_acc}')\n",
    "            global_model_accuracies.append(clean_acc)\n",
    "            self.cache[f\"unlearning_client_models\"] = client_models\n",
    "            self.cache[f\"unlearning_global_models\"] = current_model_state_dict\n",
    "        return global_model_accuracies\n",
    "    \n",
    "    def unlearnAggregate(self, client_models, client_to_be_erased):\n",
    "        selected_parties = [i for i in range(len(client_models))]\n",
    "        aggregated_model_state_dict = self.average_selected_models(selected_parties, client_models)\n",
    "        return aggregated_model_state_dict\n",
    "    \n",
    "    def unlearnedModelAggregation(self, trainloader_lst, testloader, unlearned_model, num_rounds=10, client_to_be_erased=100):\n",
    "\n",
    "        num_parties = self.num_parties\n",
    "        initial_model = FMNIST_Net()\n",
    "        current_model_state_dict = copy.deepcopy(unlearned_model.state_dict())  \n",
    "        initial_model.load_state_dict(current_model_state_dict)  \n",
    "        model_dict = copy.deepcopy(initial_model.state_dict())\n",
    "        global_model_accuracies = []\n",
    "        for round_num in range(num_rounds): \n",
    "            ##################### Local Training Round #############################\n",
    "            current_model_state_dict = copy.deepcopy(model_dict)\n",
    "            current_model = copy.deepcopy(initial_model)\n",
    "            current_model.load_state_dict(current_model_state_dict)\n",
    "            client_models = []\n",
    "            party_losses = []\n",
    "            for party_id in range(num_parties):\n",
    "\n",
    "                if party_id == client_to_be_erased:\n",
    "                    client_models.append(FMNIST_Net())\n",
    "                else:\n",
    "                    model = copy.deepcopy(current_model)\n",
    "                    local_training = Training(num_updates_in_epoch=None, num_local_epochs=1)\n",
    "                    model_update, party_loss = local_training.train(model=model, \n",
    "                                                trainloader=trainloader_lst[party_id], \n",
    "                                                criterion=None, opt=None, dataType=\"FMNIST\")\n",
    "\n",
    "                    client_models.append(copy.deepcopy(model_update))\n",
    "                    party_losses.append(party_loss)\n",
    "                    print(f\"Party {party_id} Loss: {party_loss}\")\n",
    "            ######################################################################  \n",
    "            current_model_state_dict = self.unlearnAggregate(client_models=client_models, client_to_be_erased=client_to_be_erased)\n",
    "            model_dict = copy.deepcopy(current_model_state_dict)\n",
    "            eval_model = FMNIST_Net()\n",
    "            eval_model.load_state_dict(current_model_state_dict)\n",
    "            clean_acc = local_training.evaluate(testloader, eval_model)\n",
    "            # clean_accuracy[fusion_key][round_num] = clean_acc  \n",
    "            global_model_accuracies.append(clean_acc)\n",
    "            self.cache[f\"unlearning_client_models\"] = client_models\n",
    "            self.cache[f\"unlearning_global_models\"] = current_model_state_dict\n",
    "            print(f'Global Clean Accuracy, round {round_num} = {clean_acc}')\n",
    "        return global_model_accuracies\n",
    "\n",
    "    def compute_weight_contribution(self, global_model, client_updates, selected_client_idx):\n",
    "        \"\"\"\n",
    "        Compute the influence of each client's weight contribution to the global model.\n",
    "\n",
    "        :param global_model: The baseline global model (PyTorch model)\n",
    "        :param client_updates: List of model updates from each client (list of state_dicts)\n",
    "        :param selected_client_idx: Index of the client whose contribution you want to analyze\n",
    "        :return: Difference between the global model's weights with and without the selected client's contribution\n",
    "        \"\"\"\n",
    "        # Compute the average weight update with all clients\n",
    "        num_clients = len(client_updates)\n",
    "        avg_update = {key: torch.zeros_like(val) for key, val in client_updates[0].state_dict().items()}\n",
    "\n",
    "        for update in client_updates:\n",
    "            for key in update.state_dict():\n",
    "                avg_update[key] += update.state_dict()[key] / num_clients\n",
    "\n",
    "        # Compute the average weight update without the selected client\n",
    "        avg_update_without_client = {key: torch.zeros_like(val) for key, val in client_updates[0].state_dict().items()}\n",
    "\n",
    "        for i, update in enumerate(client_updates):\n",
    "            if i == selected_client_idx:\n",
    "                continue  # Skip the selected client\n",
    "            for key in update.state_dict():\n",
    "                avg_update_without_client[key] += update.state_dict()[key] / (num_clients - 1)\n",
    "\n",
    "        # Calculate the difference in the global model's weights\n",
    "        weight_difference = {key: avg_update[key] - avg_update_without_client[key] for key in avg_update}\n",
    "\n",
    "        return weight_difference\n",
    "\n",
    "    def compute_weight_norm_difference(self, weight_difference):\n",
    "        \"\"\"\n",
    "        Computes the norm of the weight differences to quantify the impact.\n",
    "\n",
    "        :param weight_difference: Dictionary containing weight differences for each layer\n",
    "        :return: Dictionary with norms for each layer\n",
    "        \"\"\"\n",
    "        norm_diff = {}\n",
    "        for layer, diff in weight_difference.items():\n",
    "            norm_diff[layer] = torch.norm(diff).item()\n",
    "        return norm_diff\n",
    "    \n",
    "    def analyze_class_bias(self, global_model, weight_difference, num_classes=10):\n",
    "        \"\"\"\n",
    "        Analyzes the class-specific impact of removing a client's weight contribution.\n",
    "\n",
    "        :param global_model: The baseline global model (PyTorch model)\n",
    "        :param weight_difference: Difference in weights with and without the selected client's contribution\n",
    "        :param num_classes: Number of classes in the dataset (e.g., 10 for MNIST)\n",
    "        :return: Impact on each class based on output layer weight differences\n",
    "        \"\"\"\n",
    "        output_layer_key = None\n",
    "\n",
    "        # Identify the output layer by checking for the appropriate layer name\n",
    "        for key in weight_difference.keys():\n",
    "            if 'weight' in key and weight_difference[key].shape[0] == num_classes:\n",
    "                output_layer_key = key\n",
    "                break\n",
    "\n",
    "        if output_layer_key is None:\n",
    "            raise ValueError(\"Could not identify the output layer in the model.\")\n",
    "\n",
    "        # Analyze the impact on each class\n",
    "        class_impact = torch.norm(weight_difference[output_layer_key], dim=1).tolist()\n",
    "        return class_impact\n",
    "\n",
    "    def summarize_and_print_results(slef, norm_diff, class_impact):\n",
    "        \"\"\"\n",
    "        Summarizes and prints the results of the weight differences and class impacts.\n",
    "\n",
    "        :param norm_diff: Dictionary containing the norms of weight differences for each layer\n",
    "        :param class_impact: List containing the impact on each class\n",
    "        \"\"\"\n",
    "        print(\"=== Summary of Weight Differences by Layer ===\")\n",
    "        print(f\"{'Layer':<20} {'Norm Difference':>20}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for layer, norm in norm_diff.items():\n",
    "            print(f\"{layer:<20} {norm:>20.6f}\")\n",
    "        \n",
    "        print(\"\\n=== Impact on Each Class ===\")\n",
    "        print(f\"{'Class':<10} {'Impact':>10}\")\n",
    "        print(\"-\" * 25)\n",
    "        \n",
    "        for class_idx, impact in enumerate(class_impact):\n",
    "            print(f\"Class {class_idx:<5} {impact:>10.6f}\")\n",
    "        \n",
    "        print(\"\\n=== Analysis ===\")\n",
    "        \n",
    "        # Find the class with the maximum and minimum impact\n",
    "        max_impact_class = max(range(len(class_impact)), key=lambda i: class_impact[i])\n",
    "        min_impact_class = min(range(len(class_impact)), key=lambda i: class_impact[i])\n",
    "        \n",
    "        print(f\"The highest impact is on Class {max_impact_class} with an impact value of {class_impact[max_impact_class]:.6f}.\")\n",
    "        print(f\"The lowest impact is on Class {min_impact_class} with an impact value of {class_impact[min_impact_class]:.6f}.\")\n",
    "\n",
    "        # Determine which layers are most and least affected\n",
    "        most_affected_layer = max(norm_diff, key=norm_diff.get)\n",
    "        least_affected_layer = min(norm_diff, key=norm_diff.get)\n",
    "        \n",
    "        print(f\"The most affected layer is '{most_affected_layer}' with a norm difference of {norm_diff[most_affected_layer]:.6f}.\")\n",
    "        print(f\"The least affected layer is '{least_affected_layer}' with a norm difference of {norm_diff[least_affected_layer]:.6f}.\")\n",
    "        print(\"\\nThis analysis suggests that removing the selected client's contribution mainly affects the above class and layer.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7b4c417cf890>\n"
     ]
    }
   ],
   "source": [
    "# Initialize the cache\n",
    "cache = Cache('./cache-federaser-10-fminst', size_limit=10*10**9)\n",
    "initial_model = FMNIST_Net()\n",
    "cache[\"initial_model\"] = initial_model\n",
    "breakpoint =  {\"round\": 5, \"status\": False}\n",
    "# Initialize the MNIST loader\n",
    "loader = DataManager(download_dir=\"./data\", normalize=True, num_clients=10)\n",
    "# Load the MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = loader.load_fashion_mnist()\n",
    "# dataLoader = loader.split_data_uneven(x_train, y_train)\n",
    "# dataLoader = loader.split_data_label_flipping(x_train, y_train)\n",
    "dataLoader = loader.split_data_extreme_minority_two(x_train, y_train, minority_classes=[3, 5])\n",
    "testDataloader = loader.get_test_dataloader(x_test, y_test)\n",
    "print(testDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Party 0 Loss: 0.3304733797764311\n",
      "Party 1 Loss: 1.8897789384310062\n",
      "Party 2 Loss: 1.9019879778990378\n",
      "Party 3 Loss: 1.8314448226065863\n",
      "Party 4 Loss: 1.8077068201133184\n",
      "Party 5 Loss: 1.7971723093872978\n",
      "Party 6 Loss: 1.782281980628059\n",
      "Party 7 Loss: 1.7857642485981895\n",
      "Party 8 Loss: 1.822745993023827\n",
      "Party 9 Loss: 1.8007869436627342\n",
      "Global Clean Accuracy, round 0 = 50.67\n",
      "Party 0 Loss: 0.13309350897868474\n",
      "Party 1 Loss: 1.0801710096689372\n",
      "Party 2 Loss: 1.0647232715900128\n",
      "Party 3 Loss: 0.8743181526660919\n",
      "Party 4 Loss: 0.8064843089807601\n",
      "Party 5 Loss: 0.8377279128347125\n",
      "Party 6 Loss: 0.8425756465821039\n",
      "Party 7 Loss: 0.7895111881551289\n",
      "Party 8 Loss: 0.7935404238246736\n",
      "Party 9 Loss: 0.83518385887146\n",
      "Global Clean Accuracy, round 1 = 57.89\n",
      "Party 0 Loss: 0.024779494714651566\n",
      "Party 1 Loss: 0.8205676961403626\n",
      "Party 2 Loss: 0.7989999886888725\n",
      "Party 3 Loss: 0.7695235695157733\n",
      "Party 4 Loss: 0.701808118394443\n",
      "Party 5 Loss: 0.7109040546984899\n",
      "Party 6 Loss: 0.6753176287526176\n",
      "Party 7 Loss: 0.695306651649021\n",
      "Party 8 Loss: 0.706288001367024\n",
      "Party 9 Loss: 0.6933546960353851\n",
      "Global Clean Accuracy, round 2 = 59.33\n",
      "Party 0 Loss: 0.1471903294371441\n",
      "Party 1 Loss: 0.8024504133141958\n",
      "Party 2 Loss: 0.81195251758282\n",
      "Party 3 Loss: 0.6377677754277274\n",
      "Party 4 Loss: 0.6382574013301304\n",
      "Party 5 Loss: 0.6413822457903907\n",
      "Party 6 Loss: 0.6024408127580371\n",
      "Party 7 Loss: 0.6099217108317784\n",
      "Party 8 Loss: 0.6469540212835584\n",
      "Party 9 Loss: 0.6033030649026235\n",
      "Global Clean Accuracy, round 3 = 74.11\n",
      "Party 0 Loss: 0.02913581873217481\n",
      "Party 1 Loss: 0.6946069013613921\n",
      "Party 2 Loss: 0.6691648358335862\n",
      "Party 3 Loss: 0.6110102179504576\n",
      "Party 4 Loss: 0.624555691367104\n",
      "Party 5 Loss: 0.5957078919524238\n",
      "Party 6 Loss: 0.5902869609140214\n",
      "Party 7 Loss: 0.6005453999553408\n",
      "Party 8 Loss: 0.6042146157650721\n",
      "Party 9 Loss: 0.5957097184090387\n",
      "Global Clean Accuracy, round 4 = 63.28\n",
      "Party 0 Loss: 0.0763593454901517\n",
      "Party 1 Loss: 0.7032407782971859\n",
      "Party 2 Loss: 0.6944386007694098\n",
      "Party 3 Loss: 0.5536580426352364\n",
      "Party 4 Loss: 0.5704498610326222\n",
      "Party 5 Loss: 0.5546444718326841\n",
      "Party 6 Loss: 0.5666103384324482\n",
      "Party 7 Loss: 0.5346946773074922\n",
      "Party 8 Loss: 0.5786202173857462\n",
      "Party 9 Loss: 0.5611595454670134\n",
      "Global Clean Accuracy, round 5 = 76.08\n",
      "Party 0 Loss: 0.026080020427277\n",
      "Party 1 Loss: 0.6277883901045873\n",
      "Party 2 Loss: 0.6011428738442751\n",
      "Party 3 Loss: 0.5538119098969868\n",
      "Party 4 Loss: 0.5749648781049819\n",
      "Party 5 Loss: 0.560706377738998\n",
      "Party 6 Loss: 0.5429808894793192\n",
      "Party 7 Loss: 0.5695166545254844\n",
      "Party 8 Loss: 0.5438975046078364\n",
      "Party 9 Loss: 0.547129919841176\n",
      "Global Clean Accuracy, round 6 = 67.36\n",
      "Party 0 Loss: 0.05211082922993228\n",
      "Party 1 Loss: 0.6111176412266034\n",
      "Party 2 Loss: 0.6189384380212197\n",
      "Party 3 Loss: 0.5205351930289042\n",
      "Party 4 Loss: 0.5281984231301716\n",
      "Party 5 Loss: 0.5309856165023077\n",
      "Party 6 Loss: 0.5223208140759241\n",
      "Party 7 Loss: 0.5087150867496218\n",
      "Party 8 Loss: 0.5317881923346293\n",
      "Party 9 Loss: 0.5069667320875895\n",
      "Global Clean Accuracy, round 7 = 77.05\n",
      "Party 0 Loss: 0.024934669708406243\n",
      "Party 1 Loss: 0.5930920266188108\n",
      "Party 2 Loss: 0.5670635018211144\n",
      "Party 3 Loss: 0.496290589372317\n",
      "Party 4 Loss: 0.5190318297772181\n",
      "Party 5 Loss: 0.510339060000011\n",
      "Party 6 Loss: 0.5188860283011482\n",
      "Party 7 Loss: 0.5027714761949721\n",
      "Party 8 Loss: 0.5113496624288105\n",
      "Party 9 Loss: 0.5157426964669001\n",
      "Global Clean Accuracy, round 8 = 70.58\n",
      "Party 0 Loss: 0.048203061106723906\n",
      "Party 1 Loss: 0.5677528719489391\n",
      "Party 2 Loss: 0.5653838028128331\n",
      "Party 3 Loss: 0.4922273187410264\n",
      "Party 4 Loss: 0.4999190008356458\n",
      "Party 5 Loss: 0.4893567178930555\n",
      "Party 6 Loss: 0.49284503644420985\n",
      "Party 7 Loss: 0.4852478773820968\n",
      "Party 8 Loss: 0.4960982607943671\n",
      "Party 9 Loss: 0.4751871107589631\n",
      "Global Clean Accuracy, round 9 = 79.52\n",
      "Party 0 Loss: 0.02077272037306102\n",
      "Party 1 Loss: 0.5308763144107965\n",
      "Party 2 Loss: 0.53033458842681\n",
      "Party 3 Loss: 0.48277994990348816\n",
      "Party 4 Loss: 0.4986179925146557\n",
      "Party 5 Loss: 0.4803598885025297\n",
      "Party 6 Loss: 0.4702170995019731\n",
      "Party 7 Loss: 0.47366411132471903\n",
      "Party 8 Loss: 0.47416638547465917\n",
      "Party 9 Loss: 0.47212619795685723\n",
      "Global Clean Accuracy, round 10 = 71.3\n",
      "Party 0 Loss: 0.037969889616336634\n",
      "Party 1 Loss: 0.5590913725587038\n",
      "Party 2 Loss: 0.5280123834426587\n",
      "Party 3 Loss: 0.4607090275912058\n",
      "Party 4 Loss: 0.4679361177342279\n",
      "Party 5 Loss: 0.4609587611187072\n",
      "Party 6 Loss: 0.44876611090841745\n",
      "Party 7 Loss: 0.4516209073009945\n",
      "Party 8 Loss: 0.45918830590588705\n",
      "Party 9 Loss: 0.45428825489112307\n",
      "Global Clean Accuracy, round 11 = 81.46\n",
      "Party 0 Loss: 0.02112990159165444\n",
      "Party 1 Loss: 0.5060850656949557\n",
      "Party 2 Loss: 0.48967355489730835\n",
      "Party 3 Loss: 0.436348414846829\n",
      "Party 4 Loss: 0.45109348921548753\n",
      "Party 5 Loss: 0.45837190605345224\n",
      "Party 6 Loss: 0.43945140427067164\n",
      "Party 7 Loss: 0.4465777902376084\n",
      "Party 8 Loss: 0.45397025630587623\n",
      "Party 9 Loss: 0.4409829314265932\n",
      "Global Clean Accuracy, round 12 = 72.4\n",
      "Party 0 Loss: 0.03855379712151868\n",
      "Party 1 Loss: 0.5149117112159729\n",
      "Party 2 Loss: 0.49475198124463743\n",
      "Party 3 Loss: 0.4200056322983333\n",
      "Party 4 Loss: 0.43742959130377995\n",
      "Party 5 Loss: 0.43665556325798943\n",
      "Party 6 Loss: 0.4263133151190622\n",
      "Party 7 Loss: 0.42547879332587835\n",
      "Party 8 Loss: 0.4351013082833517\n",
      "Party 9 Loss: 0.418133067942801\n",
      "Global Clean Accuracy, round 13 = 82.43\n",
      "Party 0 Loss: 0.015978396794574412\n",
      "Party 1 Loss: 0.46495260441532504\n",
      "Party 2 Loss: 0.4704629022341508\n",
      "Party 3 Loss: 0.4282857733113425\n",
      "Party 4 Loss: 0.4317257666871661\n",
      "Party 5 Loss: 0.43592910042830874\n",
      "Party 6 Loss: 0.42653797495932805\n",
      "Party 7 Loss: 0.41420168465092067\n",
      "Party 8 Loss: 0.4269185584215891\n",
      "Party 9 Loss: 0.4199859514122918\n",
      "Global Clean Accuracy, round 14 = 73.01\n"
     ]
    }
   ],
   "source": [
    "parties = 10\n",
    "sim = FULDebug(cache, breakpoint, parties, 15)\n",
    "sim.partiesStart(dataLoader, testDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[FedEraser] Adjusted local_epoch for forgetting = 3\n",
      "[FedEraser] Unlearning will run for 9 global epochs\n",
      "------ FedEraser Global Epoch = 1 ------\n",
      "Warning: 'testloader' is not a DataLoader. Please check usage.\n",
      "Poison accuracy before unlearning step = 0.00%\n",
      "Clean test accuracy after unlearning step = 60.32%\n",
      "------ FedEraser Global Epoch = 2 ------\n",
      "Warning: 'testloader' is not a DataLoader. Please check usage.\n",
      "Poison accuracy before unlearning step = 0.00%\n"
     ]
    }
   ],
   "source": [
    "from Ful_Algo.federaser import FedEraser\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Usage example\n",
    "unlearning_instance = FedEraser(\n",
    "    client_models=cache.get(\"client_models\"),\n",
    "    global_model=cache.get(\"global_models\"),\n",
    "    num_parties=parties,  # Example value\n",
    "    party_to_be_erased=0,  # Example value\n",
    "    trainloader_lst=dataLoader,\n",
    "    testloader=testDataloader,\n",
    "    testloader_poison=dataLoader,\n",
    "    initial_model=FMNIST_Net(),\n",
    "    selected_CMs=cache.get(\"client_models_all_rounds\"),\n",
    "    selected_GMs=cache.get(\"global_models_all_rounds\"),\n",
    "    unlearn_global_models=cache.get(\"global_models_all_rounds\"),\n",
    "    lr=0.01,\n",
    "    global_epoch=9\n",
    ")\n",
    "\n",
    "unlearned_model = unlearning_instance.execute_unlearning()\n",
    "cache[\"unlearned_model\"] = unlearned_model[-1]\n",
    "unlearned_model = unlearned_model[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = FULDebug(cache, breakpoint, parties, 10)\n",
    "global_model_accuracies_without_FULDebug = sim.unlearnedModelAggregation(dataLoader, testDataloader, unlearned_model, num_rounds=5, client_to_be_erased=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = FULDebug(cache, breakpoint, parties, 10)\n",
    "global_model_accuracies_with_FULDebug = sim.unlearnedModelAggregationWithSelectedClients(dataLoader, testDataloader, unlearned_model, num_rounds=5, client_to_be_erased=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both arrays into a DataFrame\n",
    "import pandas as pd\n",
    "filename = \"results_fmnist_client_selection_effiency_federaser-25.csv\"\n",
    "df = pd.DataFrame({\n",
    "    'Without_FULDebug': global_model_accuracies_without_FULDebug,\n",
    "    'With_FULDebug': global_model_accuracies_with_FULDebug\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(filename, index=False)\n",
    "print(f\"Accuracies saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "analytics = Analytics(cache)\n",
    "analytics.client_vs_global_per_class_accuracy(0, testDataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.unlearned_model_vs_global_per_class_accuracy(testDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.global_before_vs_global_after_per_class_accuracy(testDataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.visualize_feature_comparison(client_idx=0, testDataloader=testDataloader, num_images_to_visualize=5, visualization_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.display_classwise_metrics(0, testDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.display_feature_summary(0, testDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.display_client_contributions_to_calss_compared_to_others(0, testDataloader, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.plot_client_contributions_to_calss_compared_to_others(0, testDataloader, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.visualize_feature_change_class_wise_shared_unlearned_model(client_idx=0, testDataloader=testDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.visualize_feature_change_class_wise(client_idx=0, testDataloader=testDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.plot_mean_feature_deviation(client_idx=0, test_loader=testDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "analytics = Analytics(cache)\n",
    "analytics.plot_shap_comparison(0, testDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Define a function to compute cosine similarity between two sets of outputs\n",
    "def cosine_similarity(outputs1, outputs2):\n",
    "    return 1 - cosine(outputs1.flatten(), outputs2.flatten())\n",
    "\n",
    "# Define a function to compute KL divergence between two sets of outputs\n",
    "def kl_divergence(outputs1, outputs2):\n",
    "    p = torch.softmax(outputs1, dim=1).numpy()\n",
    "    q = torch.softmax(outputs2, dim=1).numpy()\n",
    "    return np.sum(p * np.log(p / q))\n",
    "    \n",
    "# Define a function to generate synthetic inputs\n",
    "def generate_synthetic_inputs(num_samples, input_shape):\n",
    "    \"\"\"\n",
    "    Generate random synthetic inputs.\n",
    "    :param num_samples: Number of samples to generate.\n",
    "    :param input_shape: Shape of each input sample (e.g., [1, 28, 28] for MNIST).\n",
    "    :return: Synthetic inputs as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    return torch.randn(num_samples, *input_shape)\n",
    "\n",
    "# Define a function to generate a proxy dataset using the client's model\n",
    "def build_proxy_dataset(client_model, num_samples=1000, input_shape=(1, 28, 28)):\n",
    "    \"\"\"\n",
    "    Build a proxy dataset using the client's model.\n",
    "    :param client_model: The client's model.\n",
    "    :param num_samples: Number of samples in the proxy dataset.\n",
    "    :param input_shape: Shape of each input sample.\n",
    "    :return: A TensorDataset containing synthetic inputs and outputs.\n",
    "    \"\"\"\n",
    "    # Generate synthetic inputs\n",
    "    synthetic_inputs = generate_synthetic_inputs(num_samples, input_shape)\n",
    "    \n",
    "    # Use the client's model to generate outputs\n",
    "    client_model.eval()\n",
    "    with torch.no_grad():\n",
    "        synthetic_outputs = client_model(synthetic_inputs)\n",
    "    \n",
    "    # Create a proxy dataset\n",
    "    proxy_dataset = TensorDataset(synthetic_inputs, synthetic_outputs)\n",
    "    return proxy_dataset\n",
    "\n",
    "# Define a function to compare model outputs\n",
    "def compare_model_outputs(model1, model2, dataloader):\n",
    "    similarities = []\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs1 = model1(images)\n",
    "            outputs2 = model2(images)\n",
    "            similarity = cosine_similarity(outputs1, outputs2)\n",
    "            similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "    \n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the client's model (replace with your actual model)\n",
    "    model_before = cache.get('initial_model')\n",
    "    model_before.load_state_dict(cache.get('global_models'))\n",
    "    model_before.eval()\n",
    "    \n",
    "    model_after = cache.get('initial_model')\n",
    "    model_after.load_state_dict(cache.get(\"unlearned_model\").state_dict())\n",
    "    model_after.eval()\n",
    "    \n",
    "    client_model = cache.get('initial_model')\n",
    "    client_model.load_state_dict(cache.get(\"client_models\")[0].state_dict())\n",
    "    client_model.eval()\n",
    "\n",
    "    # Build the proxy dataset\n",
    "    proxy_dataset = build_proxy_dataset(client_model, num_samples=1000, input_shape=(1, 28, 28))\n",
    "\n",
    "    # Use the proxy dataset for unlearning verification\n",
    "    dataloader = DataLoader(proxy_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Step 1: Compare global model (before unlearning) with client model on proxy dataset\n",
    "    similarity_before = compare_model_outputs(model_before, client_model, dataloader)\n",
    "    print(f\"Similarity before unlearning: {similarity_before:.4f}\")\n",
    "\n",
    "    # Step 2: Compare global model (after unlearning) with client model on proxy dataset\n",
    "    similarity_after = compare_model_outputs(model_after, client_model, dataloader)\n",
    "    print(f\"Similarity after unlearning: {similarity_after:.4f}\")\n",
    "\n",
    "    # Step 3: Evaluate unlearning\n",
    "    if similarity_before - similarity_after > 0.15:\n",
    "        print(\"Unlearning was successful: The global model has diverged from the client model on the proxy dataset.\")\n",
    "    else:\n",
    "        print(\"Unlearning may not be successful: The global model is still similar to the client model on the proxy dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
